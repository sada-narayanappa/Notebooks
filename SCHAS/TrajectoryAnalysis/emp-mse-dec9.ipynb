{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Empirical MSE for changing environment\n",
    "#Uses new f_ave calculation weighting all times equally to new p(t) one.\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm;\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random;\n",
    "import numpy;\n",
    "import scipy.integrate as integrate;\n",
    "import scipy.special as special;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Path Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Mean Times in seconds: \n",
      "[960, 900, 1020, 1140, 1050]\n",
      "\n",
      "Path Standard Deviation of Times in seconds: \n",
      "[60, 45, 70, 75, 65]\n",
      "\n",
      "Path Distances in miles:\n",
      "[8.9, 10.2, 8.4, 8.6, 8.9]\n",
      "\n",
      "Path Percent in each Region: \n",
      "[[0.33, 0.12, 0.3, 0, 0, 0.25, 0], [0, 0.18, 0, 0.07, 0.12, 0.32, 0.31], [0.23, 0.22, 0.3, 0, 0, 0.25, 0], [0.07, 0.22, 0.17, 0.19, 0, 0.35, 0], [0, 0.18, 0, 0.07, 0.11, 0.33, 0.31]]\n",
      "\n",
      "P_I(x):\n",
      "[0.2, 0.3, 0.3, 0.1, 0.1]\n",
      "\n",
      "P_p(x):\n",
      "[0.25, 0.2, 0.4, 0.05, 0.1]\n"
     ]
    }
   ],
   "source": [
    "pathMeanTimes = [];\n",
    "pathStdOfTimes = [];\n",
    "pathDistances = [];\n",
    "percentOfTimeInEachRegion = [];\n",
    "P_I = [];\n",
    "P_p = [];\n",
    "regionConcent = [120,110,80,200,230,100,150];\n",
    "\n",
    "#1801 Fry Street Falcon Heights, MN 55113 to 163 Bridge Street, Saint Paul, MN 55126 \n",
    "\n",
    "#via Snelling Ave and Highway 96W. #T = 16min. D = 8.9 mi\n",
    "#Follow Garden Ave to Snelling Ave\n",
    "#1 min (0.2 mi)\n",
    "#Turn left at the 2nd cross street onto Snelling Ave\n",
    "#8 min (4.9 mi)\n",
    "#Follow Hamline Ave N and Hwy 96 W to Bridge St in Shoreview\n",
    "#7 min (3.8 mi)\n",
    "pathMeanTimes.append(960);\n",
    "pathStdOfTimes.append(60);\n",
    "pathDistances.append(8.9);\n",
    "P_I.append(0.2);\n",
    "P_p.append(.25);\n",
    "percentOfTimeInEachRegion.append([.33,.12,.3,0,0,.25,0]);\n",
    "\n",
    "#via MN 36-E. T=15min. D=10.2 mi\n",
    "#Get on MN-36 E in Roseville from Snelling Ave\n",
    "#4 min (1.3 mi)\n",
    "#Continue on MN-36 E. Take Exit 113 to Rice St. Take exit 45 from I-694 W/US-10 W\n",
    "#8 min (6.7 mi)\n",
    "#Follow Rice St to Bridge St\n",
    "#4 min (2.2 mi)\n",
    "pathMeanTimes.append(900);\n",
    "pathStdOfTimes.append(45);\n",
    "pathDistances.append(10.2);\n",
    "P_I.append(0.3);\n",
    "P_p.append(.20);\n",
    "percentOfTimeInEachRegion.append([0,.18,0,.07,.12,.32,.31]);\n",
    "\n",
    "#via Snelling Ave and County Rd F. T = 17min. D = 8.4 mi\n",
    "#Follow Garden Ave to Snelling Ave\n",
    "#1 min (0.2 mi)\n",
    "#Turn left at the 2nd cross street onto Snelling Ave\n",
    "#8 min (4.9 mi)\n",
    "#Follow County Rd F West and Snail Lake Blvd to Bridge St in Shoreview\n",
    "#8 min (3.3 mi)\n",
    "pathMeanTimes.append(1020);\n",
    "pathStdOfTimes.append(70);\n",
    "pathDistances.append(8.4);\n",
    "P_I.append(0.3);\n",
    "P_p.append(.4);\n",
    "percentOfTimeInEachRegion.append([.23,.22,.3,0,0,.25,0]);\n",
    "\n",
    "#via Victorian T=19min. D = 8.6 mi\n",
    "#Follow Garden Ave to Snelling Ave\n",
    "#1 min (0.2 mi)\n",
    "#Take Victoria St N to Snail Lake Rd in Shoreview\n",
    "#16 min (7.6 mi)\n",
    "#Turn right onto Snail Lake Rd\n",
    "#2 min (0.6 mi)\n",
    "#Turn left onto Rice St\n",
    "#22 s (0.2 mi)\n",
    "#Turn left onto Bridge St\n",
    "#18 s (167 ft)\n",
    "pathMeanTimes.append(1140);\n",
    "pathStdOfTimes.append(75);\n",
    "pathDistances.append(8.6);\n",
    "P_I.append(0.1);\n",
    "P_p.append(.05);\n",
    "percentOfTimeInEachRegion.append([.07,.22,.17,.19,0,.35,0]);\n",
    "\n",
    "#via MN 36 and Rice ST. T = 17.5 min D =8.9 mi\n",
    "#Follow Garden Ave to Snelling Ave\n",
    "#1 min (0.2 mi)\n",
    "#Take MN-36 E and Rice St to Bridge St\n",
    "#16 min (8.7 mi)\n",
    "#Turn left onto Bridge St\n",
    "#18 s (167 ft)\n",
    "pathMeanTimes.append(1050);\n",
    "pathStdOfTimes.append(65);\n",
    "pathDistances.append(8.9);\n",
    "P_I.append(0.1);\n",
    "P_p.append(.1);\n",
    "percentOfTimeInEachRegion.append([0,.18,0,.07,.11,.33,.31]);\n",
    "\n",
    "print(\"Path Mean Times in seconds: \");\n",
    "print(pathMeanTimes);\n",
    "print(\"\\nPath Standard Deviation of Times in seconds: \");\n",
    "print(pathStdOfTimes);\n",
    "print(\"\\nPath Distances in miles:\");\n",
    "print(pathDistances);\n",
    "print(\"\\nPath Percent in each Region: \");\n",
    "print(percentOfTimeInEachRegion);\n",
    "print(\"\\nP_I(x):\");\n",
    "print(P_I);\n",
    "print(\"\\nP_p(x):\")\n",
    "print(P_p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2, 0.3, 0.4, 0.1, 0.0], [3.0, 4.0, 5.0, 2.0, 1.0], [646.2897365234671, 662.3229018279661, 794.6772984761365, 563.1666634964495, 0], [529.60540353204681, 428.4641441974361, 437.86666898631012, 689.73559159331819, 0.63245553203367588], 10]\n"
     ]
    }
   ],
   "source": [
    "#initial values\n",
    "#runs = 21;\n",
    "updateInterval = 1;\n",
    "\n",
    "def trainingsession(runs):#returns [px,tdf,tloc,tscale] for 'runs' number of test runs\n",
    "    N = runs;\n",
    "\n",
    "    pi_m = [];\n",
    "    pi_s = [];\n",
    "    numberOfTimesRouteTaken = [0,0,0,0,0];\n",
    "    routeTravelTimes=[[],[],[],[],[]]; #stores only history since last update\n",
    "    allRouteTravelTimes=[[],[],[],[],[]]; #stores all the history\n",
    "\n",
    "    m = [0,0,0,0,0];\n",
    "    c=[0,0,0,0,0];\n",
    "    tbar=[0,0,0,0,0];\n",
    "    sumtijsquared = [0,0,0,0,0]; \n",
    "    v=[1,1,1,1,1];\n",
    "    a = [0.5,0.5,0.5,0.5,0.5];\n",
    "    b = [0.1,0.1,0.1,0.1,0.1];   \n",
    "\n",
    "#tdistribution params\n",
    "    tloc = [950,930,1000,1090,1100]; #mean\n",
    "    tscale = [50, 60, 65, 80, 55]; #\"stdedv\"\n",
    "    tdf = [1,1,1,1,1]; #degrees of freedom\n",
    "\n",
    "    ptx = [0,0,0,0,0]; # probability of time t given route x\n",
    "    px = [0,0,0,0,0]; # probability of route x\n",
    "    pbxt = [0,0,0,0,0]; # probability of route x given time t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for x in range(0,N):\n",
    "    \n",
    "        #Pick a random path based on P_I\n",
    "        randomNumber = random.uniform(0,1);\n",
    "        pathLimit=0;\n",
    "        for r in range(0,len(P_I)):\n",
    "            pathLimit = pathLimit+P_I[r];\n",
    "            if(randomNumber<pathLimit):\n",
    "                randomPath = r;\n",
    "                break;\n",
    "        #print(\"\\nPath: \"+str(randomPath));\n",
    "    \n",
    "        #Find a random time that it took for that path based on normal distribution for that path\n",
    "        pathUserTime = random.normalvariate(pathMeanTimes[randomPath],pathStdOfTimes[randomPath]);\n",
    "        #print(\"User Time in Seconds: \"+str(pathUserTime));\n",
    "        routeTravelTimes[randomPath].append(pathUserTime);\n",
    "        allRouteTravelTimes[randomPath].append(pathUserTime);\n",
    "        numberOfTimesRouteTaken[randomPath] = numberOfTimesRouteTaken[randomPath] + 1;\n",
    "        c[randomPath] = c[randomPath]+1;\n",
    "        tbar[randomPath] = (tbar[randomPath]*(len(routeTravelTimes[randomPath])-1)+pathUserTime)/len(routeTravelTimes[randomPath]);\n",
    "        sumtijsquared[randomPath] = sumtijsquared[randomPath] + pow(pathUserTime,2);\n",
    "    \n",
    "        #Calculate actual time in each weather region\n",
    "        actualTimeInEachRegion = [];    \n",
    "        for r in range(0,len(percentOfTimeInEachRegion[randomPath])):\n",
    "            actualTimeInEachRegion.append(percentOfTimeInEachRegion[randomPath][r]*pathUserTime);\n",
    "        \n",
    "        #print(\"Time in each region: \"+str(actualTimeInEachRegion));\n",
    "    \n",
    "        #print(\"tbar: \" + str(tbar[randomPath]));\n",
    "        #print(\"c: \" + str(c[randomPath]) );\n",
    "        #print(\"sumtijsquared: \" + str(sumtijsquared[randomPath]) );\n",
    "    \n",
    "        if(c[randomPath]%updateInterval==0):\n",
    "            #Update prior hyperparameters\n",
    "            oldm = m[randomPath];\n",
    "            oldv = v[randomPath];\n",
    "            olda = a[randomPath];\n",
    "            oldb = b[randomPath];\n",
    "\n",
    "            v[randomPath] = oldv/(1+c[randomPath]*oldv);\n",
    "            m[randomPath] = (oldm/oldv+c[randomPath]*tbar[randomPath])*v[randomPath]        \n",
    "            a[randomPath] = olda+c[randomPath]/2;\n",
    "\n",
    "            b[randomPath] = oldb + (1/2)*(pow(oldm,2)/oldv+sumtijsquared[randomPath]-pow(m[randomPath],2)/v[randomPath]);\n",
    "        \n",
    "            c[randomPath] = 0; \n",
    "            tbar[randomPath] = 0;\n",
    "            sumtijsquared[randomPath] = 0;\n",
    "            routeTravelTimes[randomPath] = [];\n",
    "        \n",
    "            #print(\"UPDATED HYPER PARAMS \\nm: \"+str(m[randomPath])+\n",
    "            #\"\\nv: \" + str(v[randomPath]) + \n",
    "            #\"\\na: \" + str(a[randomPath]) +\n",
    "            #\"\\nb: \" + str(b[randomPath]));\n",
    "        \n",
    "            #Update Tdistribution params\n",
    "    for x in range(0,len(numberOfTimesRouteTaken)):    \n",
    "        tloc[x] = m[x];\n",
    "        tscale[x] = numpy.sqrt(b[x]*(1+v[x])/(a[x])); # should be under sqrt?\n",
    "        tdf[x] = 2*a[x]; #2a?\n",
    "        #tdf[x] = a[x];\n",
    "        #print(str(tdf[x]));\n",
    "        \n",
    "#print(\"\\n Sum of numberOfTimesRouteTaken = \"+str(sum(numberOfTimesRouteTaken))); # just checking my understanding.\n",
    "#print(\"\\n N = \"+str(N)); # just checking my understanding.\n",
    "        \n",
    "#p(t|x)\n",
    "#print(\"\\nProbabilities for t =\"+str(pathUserTime)+\" (generated from route number \"+str(randomPath)+\").\"); #using only the most recent travel time, pathUserTime for now.\n",
    "#for x in range(0,len(numberOfTimesRouteTaken)):\n",
    "#    print(\"ROUTE \"+str(x)+\"df = \"+str(tdf[x]));\n",
    "#    arr = numpy.array(allRouteTravelTimes[x]);\n",
    "    #std = numpy.std(arr, axis=0); #used for delta t in p(t) calc.\n",
    "#    std = 20;\n",
    "#    tinterval = (1/20)*std;\n",
    "    #ptx[x]=tdf[x]/5;\n",
    "    #ptx[x] = t.cdf(pathUserTime+tinterval, 8, 1, 4)-t.cdf(pathUserTime-tinterval,  8, 1, 4);\n",
    "#    ptx[x] = t.cdf(pathUserTime+tinterval, tdf[x], tloc[x], tscale[x])-t.cdf(pathUserTime-tinterval,  tdf[x], tloc[x], tscale[x]);\n",
    "#    print(\"p(t|x): \"+str(ptx[x]));\n",
    "#    px[x] = numberOfTimesRouteTaken[x]/sum(numberOfTimesRouteTaken);\n",
    "#    print(\"p(x): \"+str(px[x]));\n",
    "\n",
    "#sumOfProbabilities = 0;\n",
    "#for x in range(0,len(numberOfTimesRouteTaken)):    \n",
    "#    sumOfProbabilities = sumOfProbabilities + ptx[x]*px[x]; #this is p(t)\n",
    "\n",
    "#for x in range(0,len(numberOfTimesRouteTaken)):     \n",
    "#    pbxt[x] = (ptx[x]*px[x])/sumOfProbabilities;\n",
    "#    print(\"Route \" + str(x) +\" pb(x|t): \"+str(pbxt[x]));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"\\nProbabilities for t =\"+str(pathUserTime)+\" (generated from route number \"+str(randomPath)+\").\"); #using only the most recent travel time, pathUserTime for now.\n",
    "    for x in range(0,len(numberOfTimesRouteTaken)):\n",
    "        #print(\"ROUTE \"+str(x)+\"df = \"+str(tdf[x]));\n",
    "        #arr = numpy.array(allRouteTravelTimes[x]);\n",
    "        #std = numpy.std(arr, axis=0); #used for delta t in p(t) calc.\n",
    "        #std = 20;\n",
    "        #tinterval = (1/20)*std;\n",
    "        ptx[x] = t.pdf(pathUserTime, tdf[x], tloc[x], tscale[x]);#this is p(t|x)\n",
    "        #print(\"p(t|x): \"+str(ptx[x]));\n",
    "        px[x] = numberOfTimesRouteTaken[x]/sum(numberOfTimesRouteTaken); #this is p(x)\n",
    "        #print(\"p(x): \"+str(px[x]));\n",
    "\n",
    "    sumOfProbabilities = 0;\n",
    "    for x in range(0,len(numberOfTimesRouteTaken)):    \n",
    "        sumOfProbabilities = sumOfProbabilities + ptx[x]*px[x]; #this is p(t)\n",
    "\n",
    "    for x in range(0,len(numberOfTimesRouteTaken)):     \n",
    "        pbxt[x] = (ptx[x]*px[x])/sumOfProbabilities; #this is p(x|t)\n",
    "        #print(\"Route \" + str(x) +\" pb(x|t): \"+str(pbxt[x]));\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"\\n Sum of prob x given t = \"+str(sum(pbxt))); # just checking my understanding.\n",
    "\n",
    "    estimateInEachRegion = []\n",
    "    #Estimated exposure\n",
    "    for j in range(0,len(actualTimeInEachRegion)):\n",
    "        estimateForThisRegion = 0;\n",
    "        for i in range(0,len(numberOfTimesRouteTaken)): #len(numberOfTimesRouteTaken)= number of candidate paths\n",
    "            estimateForThisRegion = estimateForThisRegion+percentOfTimeInEachRegion[i][j]*pathUserTime*pbxt[i];\n",
    "        estimateInEachRegion.append(estimateForThisRegion);\n",
    "\n",
    "    #print(\"Estimated Exposure: \" + str(estimateInEachRegion));\n",
    "    #print(\"g(t) =\"+str(sum(estimateInEachRegion)));\n",
    "    return [px,tdf,tloc,tscale,runs]\n",
    "\n",
    "print(str(trainingsession(10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(numberOfPaths,pathAndTime,trainingDays,mInit):#minit = list of initialization for m\n",
    "    m = mInit;\n",
    "    c=[];\n",
    "    tbarTotal=[];\n",
    "    tbar = [];\n",
    "    sumtijsquared = [];\n",
    "    numberOfTimesRouteTaken = [];\n",
    "    v=[];\n",
    "    a = [];\n",
    "    b = [];\n",
    "    px = [];\n",
    "    tloc = [];\n",
    "    tscale = [];\n",
    "    tdf = [];\n",
    "    for path in range(0,numberOfPaths):\n",
    "        c.append(0);\n",
    "        v.append(1);\n",
    "        a.append(0.01);\n",
    "        b.append(0.01);\n",
    "        c.append(0);\n",
    "        tbarTotal.append(0);\n",
    "        tbar.append(0);\n",
    "        sumtijsquared.append(0);\n",
    "        \n",
    "        #numberOfTimesRouteTaken.append(0);\n",
    "    for day in range(0,trainingDays):\n",
    "        path = pathAndTime[day][0];\n",
    "        c[path] = c[path]+1;\n",
    "        sumtijsquared[path] = sumtijsquared[path] + pathAndTime[day][1]**2;\n",
    "        tbarTotal[path] = tbarTotal[path] + pathAndTime[day][1];\n",
    "    for path in range(0,numberOfPaths):\n",
    "        if c[path]==0:\n",
    "            tbar[path]=0;\n",
    "        else:\n",
    "            tbar[path] = tbarTotal[path]/c[path];\n",
    "        \n",
    "\n",
    "    for path in range(0,numberOfPaths):\n",
    "        oldm = m[path];\n",
    "        oldv = v[path];\n",
    "        olda = a[path];\n",
    "        oldb = b[path];\n",
    "    \n",
    "    \n",
    "        v[path] = oldv/(1+c[path]*oldv);\n",
    "        m[path] = (oldm/oldv+c[path]*tbar[path])*v[path];\n",
    "        a[path] = olda+c[path]/2;\n",
    "        b[path] = oldb + (1/2)*(pow(oldm,2)/oldv+sumtijsquared[path]-pow(m[path],2)/v[path]);\n",
    "        tloc.append(m[path]);\n",
    "        tscale.append(numpy.sqrt(b[path]*(1+v[path])/(a[path])));\n",
    "        tdf.append(2*a[path]);\n",
    "        px.append(c[path]/trainingDays);\n",
    "        \n",
    "    return [px,tdf,tloc,tscale,trainingDays];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pt(t,pind,indPathMeans,indPathStds): #calculates true probability of time t for:\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    total = 0;\n",
    "    for i in range(0,len(pind)):\n",
    "        total = total + norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#determining f(x,t) and average value\n",
    "\n",
    "\n",
    "low = -1000\n",
    "high = 3000\n",
    "#These are the limits of integraton for time in the average value calculations for f_ave and for the MSE.\n",
    "#They must be carefully set so that you integrate over all significantly likely times, but not\n",
    "#so wide that you get division by 0 for times for which p(t) is indistinguishable from 0.\n",
    "\n",
    "\n",
    "\n",
    "def fexposure(path, time,concens):#path = path, time = time, concens = list of concentrations in each region\n",
    "    #requires global specification of percent of time in each reagion, percentOfTimeInEachRegion\n",
    "    #which is a list of lists.  There is one list for each path and that list is the list\n",
    "    #of percents of times that path spends in each region.  This list must be of length len(concens)\n",
    "    actualCITI = [];\n",
    "    actualTimeInEachRegion = [];    \n",
    "    for r in range(0,len(percentOfTimeInEachRegion[path])):\n",
    "        actualTimeInEachRegion.append(percentOfTimeInEachRegion[path][r]*time);\n",
    "    for regionNum in range(0,len(actualTimeInEachRegion)): #sum of atualCITI = f(x,t)\n",
    "        actualCITI.append(concens[regionNum]*actualTimeInEachRegion[regionNum]);\n",
    "    return sum(actualCITI);\n",
    "\n",
    "\n",
    "\n",
    "def avef(baseconcentrations,pind,indPathMeans,indPathStds): #average f_environ(x,t) over all routes \n",
    "    #times and environments\n",
    "    #baseconcentrations = list of base pollutant concentrations in each cell\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    newvec = []\n",
    "    for i in range (0,len(P_I)):\n",
    "        pct_conc = sum(j[0] * j[1] for j in zip(percentOfTimeInEachRegion[i], baseconcentrations))\n",
    "        newvec.append(pct_conc*pind[i]*pathMeanTimes[i]);\n",
    "    return sum(newvec);\n",
    "\n",
    "\n",
    "\n",
    "def avefold(baseconcentrations,pind,indPathMeans,indPathStds): #Old, but accurate\n",
    "    #average f_environ(x,t) over all routes \n",
    "    #times and environments\n",
    "    #baseconcentrations = list of base pollutant concentrations in each cell\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    total = 0;\n",
    "    #timeNormalization = integrate.quad(pt,low,high,args=(pind,indPathMeans,indPathStds))[0];\n",
    "    timeNormalization = 1;\n",
    "    for i in range(0,len(pind)):\n",
    "        def f(t):\n",
    "            #return fexposure(i,t,(baseconcentrations))*pt(t,pind,indPathMeans,indPathStds);\n",
    "            return fexposure(i,t,(baseconcentrations))*norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "        total = total + integrate.quad(f,low,high,args=())[0];\n",
    "    return total/timeNormalization;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating path and time list\n",
    "\n",
    "def pathAndTimeGen(days):\n",
    "    indPathAndTime = [];\n",
    "    #Pick a random path based on P_I\n",
    "    for i in range(0,days):\n",
    "        randomNumber = random.uniform(0,1);\n",
    "        pathLimit=0;\n",
    "        for r in range(0,len(P_I)):\n",
    "            pathLimit = pathLimit+P_I[r];\n",
    "            if(randomNumber<pathLimit):\n",
    "                randomPath = r;\n",
    "                break;\n",
    "        #Find a random time that it took for that path based on normal distribution for that path\n",
    "        pathUserTime = random.normalvariate(pathMeanTimes[randomPath],pathStdOfTimes[randomPath]);\n",
    "        indPathAndTime.append([randomPath,pathUserTime]);\n",
    "    return indPathAndTime;\n",
    "\n",
    "def environGen(regions,base,variation,days):#makes a list of environmental conditions\n",
    "    #for days number of days\n",
    "    #regions = number of Voronoi cells\n",
    "    #base = base concentration list, a list of length = regions\n",
    "    #variation = plus/minus range of variation in the values\n",
    "    environment = [];\n",
    "    for i in range(0,days):\n",
    "        dailyConditions = [];\n",
    "        for region in range(0,regions):\n",
    "            dailyConditions.append(base[region]+random.uniform(-variation,variation));\n",
    "        environment.append(dailyConditions);\n",
    "    return environment;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TESTING##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(str(term1[0]));\n",
    "#print(str(term2[0]));\n",
    "#print(\"ave f(x,t) = \"+str(avef()));\n",
    "#print(\"\\n\");\n",
    "#print(\"Theoretically minimal sqrt of MSE = \"+str(sqrtmse));\n",
    "#print(\"Theoretically minimal relative sqrt of MSE = \"+str(relativemse));\n",
    "#print(\"\\n\");\n",
    "#print(\"Theoretically minimal MSE =\"+str(mse));\n",
    "#print(\"Theoretically mimimal relative MSE =\"+str(mse/avef()))\n",
    "#trainedParam = trainingsession(10);\n",
    "\n",
    "#print(str(px));\n",
    "#print(str(P_I));\n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "#EMPERICAL MSE START\n",
    "\n",
    "def probtBel(time,trainedParam):#thIs is updated belief p_B(time)\n",
    "    result = 0.0;\n",
    "    for x in range(0,len(trainedParam[0])):\n",
    "        result = result + t.pdf(time, trainedParam[1][x], trainedParam[2][x], trainedParam[3][x])*trainedParam[0][x];\n",
    "    return result\n",
    "\n",
    "#print(str(probt(900)));\n",
    "\n",
    "def probxgiventBel(x,time,trainedParam):#this is updted belief p_B(x|time)\n",
    "    return t.pdf(time, trainedParam[1][x], trainedParam[2][x], trainedParam[3][x])*trainedParam[0][x]/probtBel(time,trainedParam)\n",
    "\n",
    "#print(\"2 given 900 = \"+str(probxgivent(2,900)))\n",
    "\n",
    "\n",
    "def gest(time,trainedParam, concens):#this is g(time)\n",
    "    total = 0;\n",
    "    for x in range(0,len(trainedParam[0])):\n",
    "        total = total + fexposure(x,time,concens)*probxgiventBel(x,time,trainedParam)\n",
    "    return total\n",
    "\n",
    "#print(\"g(960) = \"+str(gest(960)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def empAveSquareError(trainedParam,pathAndTime, environment, startDay, periodLength):#Returns\n",
    "    #empirically observed average square error\n",
    "    #trainedParam = individual's hyperparameters after most current training\n",
    "    #pathAndtime = list of [path,time] observations for the user on which we train and test\n",
    "    #environment = list of lists, each of which is daily conditions in the Voronoi cells\n",
    "    #startDay = first day on which to start testing\n",
    "    #periodLength = length (in days) of this testing perios\n",
    "    squaresum = 0;\n",
    "    dayContribution = 0;\n",
    "    for day in range(0,periodLength):\n",
    "        path = pathAndTime[startDay-1][0];\n",
    "        time = pathAndTime[startDay-1][1];\n",
    "        concens = environment[startDay-1];\n",
    "        dailyContribution = (fexposure(path,time,concens)-gest(time,trainedParam,concens))**2\n",
    "        squaresum = squaresum + dailyContribution;\n",
    "    return squaresum/periodLength;\n",
    "\n",
    "\n",
    "userData = pathAndTimeGen(150);\n",
    "environment = environGen(7,[1.1,1.8,1.4,0.9,1.6,1.0,1.8],0.3,150);\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#M = 100;\n",
    "#testMSE = testAveSquareError(M,trainedParam);\n",
    "#relativeTestMSE = numpy.sqrt(testMSE)/avef()\n",
    "#print(\"ave f(x,t) = \"+str(avef()));\n",
    "#print(\"\\n\");\n",
    "#print(\"Theoretically minimal sqrt of MSE = \"+str(sqrtmse));\n",
    "#print(\"Theoretically minimal relative sqrt of MSE = \"+str(relativemse));\n",
    "#print(\"\\n\");\n",
    "#print(\"Theoretically minimal MSE =\"+str(mse));\n",
    "#print(\"Theoretically mimimal relative MSE =\"+str(mse/avef()))\n",
    "\n",
    "#print(str(M)+\" run test observed average MSE = \"+str(testMSE));\n",
    "#print(str(trainedParam[4])+\" run training session.\")\n",
    "#print(str(M)+\" run test observed sqrt of average MSE = \"+str(numpy.sqrt(testMSE)))\n",
    "#print(str(M)+\" run test observed relative sqrt average MSE = \"+str(relativeTestMSE))\n",
    "#print(\"\\n\")\n",
    "#print(str(M)+\" run relative distance from optimal = \"+str((relativeTestMSE-relativemse)/relativemse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "\n",
      "\n",
      "\n",
      "ave f(x,t) = 1324.1592\n",
      "\n",
      "\n",
      "Theoretically minimal relative sqrt of MSE = 5.93216459083\n",
      "\n",
      "\n",
      "10 run training session.\n",
      "\n",
      "\n",
      "10 run test observed relative sqrt average MSE, pct = \n",
      "1.54  7.7  15.85  11.61  7.58  2.98  3.93  7.4  20.39  15.4  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average rel dist, pct = -109.342222222\n"
     ]
    }
   ],
   "source": [
    "#Multiple Empirical MSE calculations.\n",
    "\n",
    "\n",
    "#########\n",
    "#THEORETICALLY MINIMAL MSE FOR CHANGING ENVIRONMENT BEGIN\n",
    "\n",
    "\n",
    "\n",
    "low = 200\n",
    "high = 2650\n",
    "#These are the limits of integraton for time in the average value calculations for f_ave and for the MSE.\n",
    "#They must be carefully set so that you integrate over all significantly likely times, but not\n",
    "#so wide that you get division by 0 for times for which p(t) is indistinguishable from 0.\n",
    "\n",
    "#########\n",
    "#THEORETICALLY MINIMAL MSE START\n",
    "def pt(t,pind,indPathMeans,indPathStds): #calculates true probability of time t for:\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    total = 0;\n",
    "    for i in range(0,len(pind)):\n",
    "        total = total + norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "def avef(baseconcentrations,pind,indPathMeans,indPathStds): #average f_environ(x,t) over all routes \n",
    "    #times and environments\n",
    "    #baseconcentrations = list of base pollutant concentrations in each cell\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    total = 0;\n",
    "    timeNormalization = integrate.quad(pt,low,high,args=(pind,indPathMeans,indPathStds))[0];\n",
    "    for i in range(0,len(pind)):\n",
    "        def f(t):\n",
    "            return fexposure(i,t,(baseconcentrations))*pt(t,pind,indPathMeans,indPathStds);\n",
    "        total = total + integrate.quad(f,low,high,args=())[0];\n",
    "    return total/(len(pind)*timeNormalization);\n",
    "\n",
    "\n",
    "def integrand(t, concens,pind,indPathMeans,indPathStds):#integrand in the MSE calculation\n",
    "    #concens = list of pollutant concentrations in the cells\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    term1 = 0;\n",
    "    term2sum = 0;\n",
    "    term2 = 0;\n",
    "    for i in range(0,len(pathMeanTimes)):\n",
    "        term1 = term1 + ((fexposure(i,t,concens))**2)*norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    for i in range(0,len(pathMeanTimes)):\n",
    "        term2sum = term2sum + fexposure(i,t,concens)*norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    term2 = (term2sum**2)/pt(t,pind,indPathMeans,indPathStds);\n",
    "    return term1 - term2;\n",
    "\n",
    "\n",
    "def theoreticalmse(M,baseconc,confidencepct,pind,indPathMeans,indPathStds):#computes confidence interval\n",
    "    #for relative MSE with:\n",
    "    #M = number of runs (trials)\n",
    "    #baseconc = base concentration list\n",
    "    #confidencepct  = confidence level in percent\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    sqrunErAve = 0.0; #running average mean squared error\n",
    "    frunAve =  0.0; # running average average value of f_epsilon(x,t)\n",
    "    sqErtotal = 0.0; # total running square error\n",
    "    relErrorList = [];\n",
    "    errorList = [];\n",
    "    averagefValue = avef(baseconc,pind,indPathMeans,indPathStds);\n",
    "    for trial in range(0,M):\n",
    "        concens = [0,0,0,0,0,0,0];\n",
    "        for region in range(len(baseconc)):\n",
    "            concens[region] = baseconc[region];#+random.uniform(-0.9,0.9);\n",
    "        mse = integrate.quad(integrand,low,high,args=(concens,pind,indPathMeans,indPathStds))[0];\n",
    "        #integrate from low to high for about 6 standard deviations above and below mean times\n",
    "        errorList.append(mse);\n",
    "        relErrorList.append(mse/(averagefValue**2));\n",
    "        print(str(trial), end=\"\");\n",
    "    #\n",
    "    std = numpy.std(relErrorList,ddof=1); #sample stdev of observed relative error\n",
    "    tcv = t.ppf((100-confidencepct)/200,df = M-1,loc = 0, scale = 1); #critical value for our confidence\n",
    "    mseest = numpy.mean(relErrorList);\n",
    "    mseSqrtest = numpy.sqrt(mseest);\n",
    "    confidence = [mseest - (-tcv*std)/numpy.sqrt(M), mseest +(-tcv*std)/numpy.sqrt(M)];\n",
    "    #\n",
    "    msePctest = mseest*100;\n",
    "    mseSqrtPctest = mseSqrtest*100;\n",
    "    msePctConfidence = [];\n",
    "    mseSqrtPctConfidence = [];\n",
    "    for i in range(0,len(confidence)):\n",
    "        msePctConfidence.append(100*confidence[i]);\n",
    "        mseSqrtPctConfidence.append(100*numpy.sqrt(confidence[i]));\n",
    "    \n",
    "    return [msePctest,msePctConfidence,mseSqrtPctest, mseSqrtPctConfidence,confidencepct];\n",
    "\n",
    "\n",
    "#########\n",
    "#THEORETICALLY MINIMAL MSE END\n",
    "\n",
    "\n",
    "base=[1.1,1.8,1.4,0.9,1.6,1.0,1.8];\n",
    "\n",
    "theorymse = theoreticalmse(2,base,99,P_I,pathMeanTimes,pathStdOfTimes);\n",
    "\n",
    "\n",
    "relativemse = theorymse[2];\n",
    "\n",
    "\n",
    "#runs of empirical MSE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testTestsAbs = [];\n",
    "testTestsRel = [];\n",
    "reps = 10;\n",
    "concentrations=[1.1,1.8,1.4,0.9,1.6,1.0,1.8];\n",
    "trainedParam = training(5,userData,10,[0,0,0,0,0]);\n",
    "for reps in range(0,reps):\n",
    "#    trainedParam = trainingsession(10);\n",
    "    M = 10;\n",
    "    testMSE = empAveSquareError(trainedParam,userData,environment,M*reps,10);\n",
    "    relativeTestMSE = numpy.sqrt(testMSE)/avef(concentrations,P_I,pathMeanTimes,pathStdOfTimes);\n",
    "    testTestsRel.append(round(100*(relativeTestMSE-relativemse)/relativemse,2));\n",
    "    testTestsAbs.append(round(100*relativeTestMSE,2));\n",
    "    \n",
    "    \n",
    "print(\"\\n\");\n",
    "print(\"\\n\");\n",
    "print(\"ave f(x,t) = \"+str(avef(concentrations,P_I,pathMeanTimes,pathStdOfTimes)));\n",
    "print(\"\\n\");\n",
    "#print(\"Theoretically minimal sqrt of MSE = \"+str(sqrtmse));\n",
    "print(\"Theoretically minimal relative sqrt of MSE = \"+str(relativemse));\n",
    "print(\"\\n\");\n",
    "    #print(\"Theoretically minimal MSE =\"+str(mse));\n",
    "    #print(\"Theoretically mimimal relative MSE =\"+str(mse/avef()))\n",
    "\n",
    "    #print(str(M)+\" run test observed average MSE = \"+str(testMSE));\n",
    "print(str(trainedParam[4])+\" run training session.\")\n",
    "print(\"\\n\");\n",
    "    #print(str(M)+\" run test observed sqrt of average MSE = \"+str(numpy.sqrt(testMSE)))\n",
    "    \n",
    "print(str(M)+\" run test observed relative sqrt average MSE, pct = \")\n",
    "for i in range(0,reps+1):\n",
    "    print(str(testTestsAbs[i])+\"  \", end=\"\");\n",
    "print(\"\\n\");\n",
    "#print(str(M)+\" run relative distance from optimal, pct = \");\n",
    "#for i in range(0,reps+1):\n",
    "#    print(str(testTestsRel[i])+\"  \", end=\"\");\n",
    "        #print(str(M)+\" run test observed relative sqrt average MSE, pct = \"+\"\\n\"+str(testTestsAbs))\n",
    "print(\"\\n\")\n",
    "    #print(str(M)+\" run relative distance from optimal, pct = \"+\"\\n\"+str(testTestsRel));\n",
    "print(\"\\n\")\n",
    "print(\"Average rel dist, pct = \"+str(sum(testTestsRel)/reps))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
