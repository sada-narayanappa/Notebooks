{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Empirical MSE for changing environment\n",
    "#Uses new f_ave calculation weighting all times equally to new p(t) one.\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm;\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random;\n",
    "import numpy;\n",
    "import scipy.integrate as integrate;\n",
    "import scipy.special as special;\n",
    "low = 100;\n",
    "high = 2700;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Path Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Mean Times in seconds: \n",
      "[1920, 1980, 2160, 2100, 2100]\n",
      "\n",
      "Path Standard Deviation of Times in seconds: \n",
      "[120, 125, 135, 125, 130]\n",
      "\n",
      "Path Distances in miles:\n",
      "[25.9, 23.2, 24.4, 26, 25.2]\n",
      "\n",
      "Path Percent in each Region: \n",
      "[[0.2, 0.06, 0.09, 0.09, 0.08, 0.12, 0.04, 0, 0, 0, 0.12, 0, 0, 0, 0.12, 0.08, 0, 0], [0.21, 0.05, 0.11, 0, 0, 0, 0, 0.03, 0.06, 0, 0, 0.12, 0.11, 0.16, 0.08, 0.07, 0, 0], [0.21, 0.05, 0.11, 0, 0, 0, 0, 0.03, 0.06, 0, 0, 0.12, 0.16, 0.11, 0.08, 0.07, 0, 0], [0.2, 0.06, 0.09, 0.09, 0.08, 0.12, 0.04, 0, 0, 0, 0.12, 0, 0, 0, 0.04, 0.02, 0.07, 0.07], [0.21, 0.05, 0.11, 0, 0, 0, 0, 0.03, 0.06, 0.1, 0.1, 0.12, 0, 0, 0.15, 0.07, 0, 0]]\n",
      "\n",
      "P_I(x):\n",
      "[0.2, 0.4, 0.1, 0.1, 0.2]\n"
     ]
    }
   ],
   "source": [
    "pathMeanTimes = [];\n",
    "pathStdOfTimes = [];\n",
    "pathDistances = [];\n",
    "percentOfTimeInEachRegion = [];\n",
    "P_I = [];\n",
    "\n",
    "\n",
    "#from 1202 Lexington Parkway North, Saint Paul, MN 55103 to 15051 70th Street South, Hastings, MN 55033\n",
    "\n",
    "#via I-94 E. #T = 32min. D = 25.9 mi\n",
    "#Get on I-94 E\n",
    "#6 min (2.1 mi)\n",
    "#Follow I-94 E to MN-95 S/Manning Ave S in Washington County. Take exit 253 from I-94 E\n",
    "#14 min (13.9 mi)\n",
    "#Continue on MN-95 S/Manning Ave S. Drive to 70th St S in Denmark Township\n",
    "#12 min (9.9 mi) \n",
    "pathMeanTimes.append(1920);\n",
    "pathStdOfTimes.append(120);\n",
    "pathDistances.append(25.9);\n",
    "P_I.append(0.2);#actual\n",
    "#guess\n",
    "percentOfTimeInEachRegion.append([.2,.06,.09,.09,.08,.12,.04,0,0,0,.12,0,0,0,.12,.08,0,0]);\n",
    "\n",
    "#via Military Road. T=33min. D=23.2 mi\n",
    "#Get on I-94 E\n",
    "#6 min (2.1 mi)\n",
    "#Follow I-94 E and US-10 E/US-61 S/U.S Hwy 61 S to Bailey Rd/Maxwell Ave. Take the Bailey Rd/Maxwell Ave exit from US-10 E/US-61 S/U.S Hwy 61 S\n",
    "#11 min (9.8 mi)\n",
    "#Follow Military Rd to 70th St S in Denmark Township\n",
    "#16 min (11.3 mi) \n",
    "pathMeanTimes.append(1980);\n",
    "pathStdOfTimes.append(125);\n",
    "pathDistances.append(23.2);\n",
    "P_I.append(0.4);\n",
    "percentOfTimeInEachRegion.append([.21,.05,.11,0,0,0,0,.03,.06,0,0,.12,.11,.16,.08,.07,0,0]);\n",
    "\n",
    "#via US-10. T = 36min. D = 24.4 mi\n",
    "#Head south on Lexington Pkwy N toward Como Ave\n",
    "#1.8 mi\n",
    "#Use the left 2 lanes to turn left onto Concordia Ave\n",
    "#184 ft\n",
    "#Take the ramp on the left onto I-94 E\n",
    "#1.6 mi\n",
    "#Use the right 2 lanes to take exit 241B for 5th St\n",
    "#0.7 mi\n",
    "#Continue onto W 5th St\n",
    "#226 ft\n",
    "#Turn right onto 7th St W/Fort Rd\n",
    "#0.1 mi\n",
    "#Turn left onto W Kellogg Blvd\n",
    "#148 ft\n",
    "#Slight right onto Eagle St\n",
    "#0.1 mi\n",
    "#Continue onto Eagle Pkwy\n",
    "#0.2 mi\n",
    "#Turn left onto Shepard Rd\n",
    "#1.4 mi\n",
    "#Continue onto Warner Rd\n",
    "#1.8 mi\n",
    "#Turn right onto US-10 E/U.S Hwy 61 S\n",
    "#6.9 mi\n",
    "#Take the Summit Ave exit toward WA-22/70th St\n",
    "#0.3 mi\n",
    "#Use the left 2 lanes to turn left onto 70th St S/Summit Ave\n",
    "#Continue to follow 70th St S\n",
    "#4.3 mi\n",
    "#At the traffic circle, take the 1st exit onto 70th St S/Washington County Hwy 22\n",
    "#Continue to follow 70th St S\n",
    "#5.1 mi\n",
    "\n",
    "pathMeanTimes.append(2160);\n",
    "pathStdOfTimes.append(135);\n",
    "pathDistances.append(24.4);\n",
    "P_I.append(0.1);\n",
    "percentOfTimeInEachRegion.append([.21,.05,.11,0,0,0,0,.03,.06,0,0,.12,.16,.11,.08,.07,0,0]);\n",
    "\n",
    "# T=35min. D = 26 mi\n",
    "#Get on I-94 E\n",
    "#6 min (2.1 mi)\n",
    "#Follow I-94 E to MN-95 S/Manning Ave S in Washington County. Take exit 253 from I-94 E\n",
    "#14 min (13.9 mi)\n",
    "#Continue on MN-95 S/Manning Ave S. Take 40th St S and St Croix Trail S to 70th St S/Washington County Hwy 22 in Denmark Township\n",
    "#15 min (10.0 mi) \n",
    "pathMeanTimes.append(2100);\n",
    "pathStdOfTimes.append(125);\n",
    "pathDistances.append(26);\n",
    "P_I.append(0.1);\n",
    "percentOfTimeInEachRegion.append([.2,.06,.09,.09,.08,.12,.04,0,0,0,.12,0,0,0,.04,.02,.07,.07]);\n",
    "\n",
    "#via T = 35 min D =25.2 mi\n",
    "#Get on I-94 E\n",
    "#6 min (2.1 mi)\n",
    "#Follow I-94 E and US-10 E/US-61 S/U.S Hwy 61 S to Bailey Rd/Maxwell Ave. Take the Bailey Rd/Maxwell Ave exit from US-10 E/US-61 S/U.S Hwy 61 S\n",
    "#11 min (9.8 mi)\n",
    "#Follow Bailey Rd and MN-95 S/Manning Ave S to 70th St S in Denmark Township\n",
    "#18 min (13.3 mi) \n",
    "pathMeanTimes.append(2100);\n",
    "pathStdOfTimes.append(130);\n",
    "pathDistances.append(25.2);\n",
    "P_I.append(0.2);\n",
    "percentOfTimeInEachRegion.append([.21,.05,.11,0,0,0,0,.03,.06,.1,.1,.12,0,0,.15,.07,0,0]);\n",
    "\n",
    "print(\"Path Mean Times in seconds: \");\n",
    "print(pathMeanTimes);\n",
    "print(\"\\nPath Standard Deviation of Times in seconds: \");\n",
    "print(pathStdOfTimes);\n",
    "print(\"\\nPath Distances in miles:\");\n",
    "print(pathDistances);\n",
    "print(\"\\nPath Percent in each Region: \");\n",
    "print(percentOfTimeInEachRegion);\n",
    "print(\"\\nP_I(x):\");\n",
    "print(P_I);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Alternate Individual Data\n",
    "\n",
    "pathMeanTimes = [1920, 1980, 2160, 2100, 2100];\n",
    "\n",
    "pathStdOfTimes = [120, 125, 135, 125, 130];\n",
    "\n",
    "percentOfTimeInEachRegion = [[0.2, 0.06, 0.09, 0.09, 0.08, 0.12, 0.04, 0, 0, 0, 0.12, 0, 0, 0, 0.12, 0.08, 0, 0], [0.21, 0.05, 0.11, 0, 0, 0, 0, 0.03, 0.06, 0, 0, 0.12, 0.11, 0.16, 0.08, 0.07, 0, 0], [0.21, 0.05, 0.11, 0, 0, 0, 0, 0.03, 0.06, 0, 0, 0.12, 0.16, 0.11, 0.08, 0.07, 0, 0], [0.2, 0.06, 0.09, 0.09, 0.08, 0.12, 0.04, 0, 0, 0, 0.12, 0, 0, 0, 0.04, 0.02, 0.07, 0.07], [0.21, 0.05, 0.11, 0, 0, 0, 0, 0.03, 0.06, 0.1, 0.1, 0.12, 0, 0, 0.15, 0.07, 0, 0]];\n",
    "P_I = [0.2, 0.4, 0.1, 0.1, 0.2];\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(numberOfPaths,pathAndTime,trainingDays,mInit):#minit = list of initialization for m\n",
    "    m = mInit;\n",
    "    c=[];\n",
    "    tbarTotal=[];\n",
    "    tbar = [];\n",
    "    sumtijsquared = [];\n",
    "    numberOfTimesRouteTaken = [];\n",
    "    v=[];\n",
    "    a = [];\n",
    "    b = [];\n",
    "    px = [];\n",
    "    tloc = [];\n",
    "    tscale = [];\n",
    "    tdf = [];\n",
    "    for path in range(0,numberOfPaths):\n",
    "        c.append(0);\n",
    "        v.append(1);\n",
    "        a.append(0.01);\n",
    "        b.append(0.01);\n",
    "        c.append(0);\n",
    "        tbarTotal.append(0);\n",
    "        tbar.append(0);\n",
    "        sumtijsquared.append(0);\n",
    "        \n",
    "        #numberOfTimesRouteTaken.append(0);\n",
    "    for day in range(0,trainingDays):\n",
    "        path = pathAndTime[day][0];\n",
    "        c[path] = c[path]+1;\n",
    "        sumtijsquared[path] = sumtijsquared[path] + pathAndTime[day][1]**2;\n",
    "        tbarTotal[path] = tbarTotal[path] + pathAndTime[day][1];\n",
    "    for path in range(0,numberOfPaths):\n",
    "        if c[path]==0:\n",
    "            tbar[path]=0;\n",
    "        else:\n",
    "            tbar[path] = tbarTotal[path]/c[path];\n",
    "        \n",
    "\n",
    "    for path in range(0,numberOfPaths):\n",
    "        oldm = m[path];\n",
    "        oldv = v[path];\n",
    "        olda = a[path];\n",
    "        oldb = b[path];\n",
    "    \n",
    "    \n",
    "        v[path] = oldv/(1+c[path]*oldv);\n",
    "        m[path] = (oldm/oldv+c[path]*tbar[path])*v[path];\n",
    "        a[path] = olda+c[path]/2;\n",
    "        b[path] = oldb + (1/2)*(pow(oldm,2)/oldv+sumtijsquared[path]-pow(m[path],2)/v[path]);\n",
    "        tloc.append(m[path]);\n",
    "        tscale.append(numpy.sqrt(b[path]*(1+v[path])/(a[path])));\n",
    "        tdf.append(2*a[path]);\n",
    "        px.append(c[path]/trainingDays);\n",
    "        \n",
    "    return [px,tdf,tloc,tscale,trainingDays];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pt(t,pind,indPathMeans,indPathStds): #calculates true probability of time t for:\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    total = 0;\n",
    "    for i in range(0,len(pind)):\n",
    "        total = total + norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    return total\n",
    "\n",
    "def probtBel(time,trainedParam):#thIs is updated belief p_B(time)\n",
    "    result = 0.0;\n",
    "    for x in range(0,len(trainedParam[0])):\n",
    "        result = result + t.pdf(time, trainedParam[1][x], trainedParam[2][x], trainedParam[3][x])*trainedParam[0][x];\n",
    "    return result\n",
    "\n",
    "#print(str(probt(900)));\n",
    "\n",
    "def probxgiventBel(x,time,trainedParam):#this is updted belief p_B(x|time)\n",
    "    return t.pdf(time, trainedParam[1][x], trainedParam[2][x], trainedParam[3][x])*trainedParam[0][x]/probtBel(time,trainedParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#determining f(x,t) and average value\n",
    "\n",
    "\n",
    "#low = 200\n",
    "#high = 2650\n",
    "#These are the limits of integraton for time in the average value calculations for f_ave and for the MSE.\n",
    "#They must be carefully set so that you integrate over all significantly likely times, but not\n",
    "#so wide that you get division by 0 for times for which p(t) is indistinguishable from 0.\n",
    "\n",
    "\n",
    "\n",
    "def fexposure(path, time,concens):#path = path, time = time, concens = list of concentrations in each region\n",
    "    #requires global specification of percent of time in each reagion, percentOfTimeInEachRegion\n",
    "    #which is a list of lists.  There is one list for each path and that list is the list\n",
    "    #of percents of times that path spends in each region.  This list must be of length len(concens)\n",
    "    actualCITI = [];\n",
    "    actualTimeInEachRegion = [];    \n",
    "    for r in range(0,len(percentOfTimeInEachRegion[path])):\n",
    "        actualTimeInEachRegion.append(percentOfTimeInEachRegion[path][r]*time);\n",
    "    for regionNum in range(0,len(actualTimeInEachRegion)): #sum of atualCITI = f(x,t)\n",
    "        actualCITI.append(concens[regionNum]*actualTimeInEachRegion[regionNum]);\n",
    "    return sum(actualCITI);\n",
    "\n",
    "\n",
    "\n",
    "def avef(baseconcentrations,pind,indPathMeans,indPathStds): #average f_environ(x,t) over all routes \n",
    "    #times and environments\n",
    "    #baseconcentrations = list of base pollutant concentrations in each cell\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    newvec = []\n",
    "    for i in range (0,len(P_I)):\n",
    "        pct_conc = sum(j[0] * j[1] for j in zip(percentOfTimeInEachRegion[i], baseconcentrations))\n",
    "        newvec.append(pct_conc*pind[i]*pathMeanTimes[i]);\n",
    "    return sum(newvec);\n",
    "\n",
    "\n",
    "\n",
    "def avefold(baseconcentrations,pind,indPathMeans,indPathStds): #Old, but accurate\n",
    "    #average f_environ(x,t) over all routes \n",
    "    #times and environments\n",
    "    #baseconcentrations = list of base pollutant concentrations in each cell\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    total = 0;\n",
    "    #timeNormalization = integrate.quad(pt,low,high,args=(pind,indPathMeans,indPathStds))[0];\n",
    "    timeNormalization = 1;\n",
    "    for i in range(0,len(pind)):\n",
    "        def f(t):\n",
    "            #return fexposure(i,t,(baseconcentrations))*pt(t,pind,indPathMeans,indPathStds);\n",
    "            return fexposure(i,t,(baseconcentrations))*norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "        total = total + integrate.quad(f,low,high,args=())[0];\n",
    "    return total/timeNormalization;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generating path and time list\n",
    "\n",
    "def pathAndTimeGen(days,pind,indPathMeans,indPathStds):\n",
    "    indPathAndTime = [];\n",
    "    #Pick a random path based on P_I = pind\n",
    "    for i in range(0,days):\n",
    "        randomNumber = random.uniform(0,1);\n",
    "        pathLimit=0;\n",
    "        for r in range(0,len(pind)):\n",
    "            pathLimit = pathLimit+pind[r];\n",
    "            if(randomNumber<pathLimit):\n",
    "                randomPath = r;\n",
    "                break;\n",
    "        #Find a random time that it took for that path based on normal distribution for that path\n",
    "        pathUserTime = random.normalvariate(indPathMeans[randomPath],indPathStds[randomPath]);\n",
    "        indPathAndTime.append([randomPath,pathUserTime]);\n",
    "    return indPathAndTime;\n",
    "\n",
    "def environGen(regions,base,variation,days):#makes a list of environmental conditions\n",
    "    #for days number of days\n",
    "    #regions = number of Voronoi cells\n",
    "    #base = base concentration list, a list of length = regions\n",
    "    #variation = plus/minus range of variation in the values\n",
    "    environment = [];\n",
    "    for i in range(0,days):\n",
    "        dailyConditions = [];\n",
    "        for region in range(0,regions):\n",
    "            dailyConditions.append(base[region]+random.uniform(-variation,variation));\n",
    "        environment.append(dailyConditions);\n",
    "    return [environment,base];\n",
    "\n",
    "\n",
    "#userData = pathAndTimeGen(150);\n",
    "#environment = environGen(7,[1.1,1.8,1.4,0.9,1.6,1.0,1.8],0.3,3);\n",
    "\n",
    "#print(environment);\n",
    "\n",
    "#print(environment[1]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#EMPERICAL MSE START\n",
    "\n",
    "\n",
    "def gest(time,trainedParam, concens):#this is g(time)\n",
    "    total = 0;\n",
    "    for x in range(0,len(trainedParam[0])):\n",
    "        total = total + fexposure(x,time,concens)*probxgiventBel(x,time,trainedParam)\n",
    "    return total\n",
    "\n",
    "#print(\"g(960) = \"+str(gest(960)))\n",
    "\n",
    "\n",
    "def empAveSquareError(trainedParam,pathAndTime, environment, startDay, periodLength):#Returns\n",
    "    #empirically observed average square error\n",
    "    #trainedParam = individual's hyperparameters after most current training\n",
    "    #pathAndtime = list of [path,time] observations for the user on which we train and test\n",
    "    #environment = list of lists, each of which is daily conditions in the Voronoi cells\n",
    "    #startDay = first day on which to start testing.  Days start counting with 0 (!!!)\n",
    "    #periodLength = length (in days) of this testing perios\n",
    "    squaresum = 0;\n",
    "    dayContribution = 0;\n",
    "    for day in range(0,periodLength):\n",
    "        #print(startDay + day);\n",
    "        path = pathAndTime[startDay+day][0];\n",
    "        time = pathAndTime[startDay+day][1];\n",
    "        concens = environment[0][startDay+day];\n",
    "        dailyContribution = (fexposure(path,time,concens)-gest(time,trainedParam,concens))**2\n",
    "        squaresum = squaresum + dailyContribution;\n",
    "    return squaresum/periodLength;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#THEORETICALLY MINIMAL MSE FOR CHANGING ENVIRONMENT BEGIN\n",
    "\n",
    "\n",
    "\n",
    "#low = 100\n",
    "#high = 2650\n",
    "#These are the limits of integraton for time in the average value calculations for f_ave and for the MSE.\n",
    "#They must be carefully set so that you integrate over all significantly likely times, but not\n",
    "#so wide that you get division by 0 for times for which p(t) is indistinguishable from 0.\n",
    "\n",
    "#########\n",
    "#THEORETICALLY MINIMAL MSE START\n",
    "\n",
    "\n",
    "def integrand(t, concens,pind,indPathMeans,indPathStds):#integrand in the MSE calculation\n",
    "    #concens = list of pollutant concentrations in the cells\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    term1 = 0;\n",
    "    term2sum = 0;\n",
    "    term2 = 0;\n",
    "    for i in range(0,len(pathMeanTimes)):\n",
    "        term1 = term1 + ((fexposure(i,t,concens))**2)*norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    for i in range(0,len(pathMeanTimes)):\n",
    "        term2sum = term2sum + fexposure(i,t,concens)*norm.pdf(t,indPathMeans[i],indPathStds[i])*pind[i];\n",
    "    term2 = (term2sum**2)/pt(t,pind,indPathMeans,indPathStds);\n",
    "    return term1 - term2;\n",
    "\n",
    "\n",
    "def theoreticalmse(M,baseconc,confidencepct,pind,indPathMeans,indPathStds,variation):#computes confidence interval\n",
    "    #for relative MSE with:\n",
    "    #M = number of runs (trials)\n",
    "    #baseconc = base concentration list\n",
    "    #confidencepct  = confidence level in percent\n",
    "    #pind = list of individual true route selecction probabilities\n",
    "    #indPathMeans = list of individual's mean travel times on each path\n",
    "    #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "    sqrunErAve = 0.0; #running average mean squared error\n",
    "    frunAve =  0.0; # running average average value of f_epsilon(x,t)\n",
    "    sqErtotal = 0.0; # total running square error\n",
    "    relErrorList = [];\n",
    "    errorList = [];\n",
    "    averagefValue = avef(baseconc,pind,indPathMeans,indPathStds);\n",
    "    for trial in range(0,M):\n",
    "        concens = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0];\n",
    "        for region in range(len(baseconc)):\n",
    "            concens[region] = baseconc[region]+random.uniform(-variation,variation);#change environment\n",
    "        mse = integrate.quad(integrand,low,high,args=(concens,pind,indPathMeans,indPathStds))[0];\n",
    "        #integrate from low to high for about 6 standard deviations above and below mean times\n",
    "        errorList.append(mse);\n",
    "        relErrorList.append(mse/(averagefValue**2));\n",
    "        #print(str(trial), end=\"\");\n",
    "    #\n",
    "    std = numpy.std(relErrorList,ddof=1); #sample stdev of observed relative error\n",
    "    tcv = t.ppf((100-confidencepct)/200,df = M-1,loc = 0, scale = 1); #critical value for our confidence\n",
    "    mseest = numpy.mean(relErrorList);\n",
    "    mseSqrtest = numpy.sqrt(mseest);\n",
    "    confidence = [mseest - (-tcv*std)/numpy.sqrt(M), mseest +(-tcv*std)/numpy.sqrt(M)];\n",
    "    #\n",
    "    msePctest = mseest*100;\n",
    "    mseSqrtPctest = mseSqrtest*100;\n",
    "    msePctConfidence = [];\n",
    "    mseSqrtPctConfidence = [];\n",
    "    for i in range(0,len(confidence)):\n",
    "        msePctConfidence.append(100*confidence[i]);\n",
    "        mseSqrtPctConfidence.append(100*numpy.sqrt(confidence[i]));\n",
    "    \n",
    "    return [msePctest,msePctConfidence,mseSqrtPctest, mseSqrtPctConfidence,confidencepct];\n",
    "\n",
    "\n",
    "#########\n",
    "#THEORETICALLY MINIMAL MSE END\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train-test regime for one person\n",
    "\n",
    "def varRegime(pathAndTime,environment,indData,mseRuns,variation):#Train-test regime\n",
    "    #pathAndTime = list of individual's (path,time) data\n",
    "    #environment = [list of lists environmental conditions, base conditions]\n",
    "        #that is, first entry in environment is a list of lists, each of which is a list of cell \n",
    "        #conditions and the second entry is the list of base cell conditions\n",
    "    #indData = true probabilities and hyperparameter m initialization\n",
    "        # [pind, indPathMeans, indPathStds, mInit] with\n",
    "        #pind = list of individual true route selecction probabilities\n",
    "        #indPathMeans = list of individual's mean travel times on each path\n",
    "        #indPathStds = list of individual's standard deviations of travel times on each path\n",
    "        #mInit = initialization of hyperparameter m\n",
    "    #mseRuns = number of runs with which to estimate theoretical MSE (does not use pathAndTime)\n",
    "    #variation = amount of variation on base conditions with respect to which to estimate theory MSE\n",
    "    empMSElist = [[],[],[],[]];# list of emp mse lists for train of 5, 10, 20, 40\n",
    "    numberOfPaths = len(indData[0]);\n",
    "    #theoryMse = 5.28832505349;#DEBUG MSE TO SAVE TIME\n",
    "    averagef  = avef(environment[1],indData[0],indData[1],indData[2]);\n",
    "    #thMseConf = theoreticalmse(mseRuns,environment[1],99.9,indData[0],indData[1],indData[2],variation);\n",
    "    #theoryMse = thMseConf[2];\n",
    "    #theoryMse = theoreticalmse(mseRuns,environment[1],50,indData[0],indData[1],indData[2],variation)[2];\n",
    "    for trainCycle in range(0,len(empMSElist)):\n",
    "        cycleStartDay = 100+((trainCycle)*4000);#Cycle's test start date (not train start date)\n",
    "        cycleAveSqErr = 0;\n",
    "        trainedParam = [];\n",
    "        trainedParam = training(numberOfPaths,pathAndTime,5*(2**trainCycle),indData[3]);\n",
    "        #startDay = TrainDuration[cycle];\n",
    "        prefixused = 0;\n",
    "        for i in range(0,9):            \n",
    "            testMSE = empAveSquareError(trainedParam,pathAndTime,environment[0],cycleStartDay+prefixused,i+1);\n",
    "            empMSElist[trainCycle].append(100*numpy.sqrt(testMSE)/averagef);\n",
    "            prefixused = prefixused + i+1;\n",
    "        used = 0;\n",
    "        for testCycle in range(0,25):\n",
    "            period = 10*(testCycle+1);\n",
    "            startDay = 100+cycleStartDay + used;\n",
    "            testMSE = empAveSquareError(trainedParam,pathAndTime,environment[0],startDay,period);\n",
    "            used = used + period;\n",
    "            empMSElist[trainCycle].append(100*numpy.sqrt(testMSE)/averagef);\n",
    "        \n",
    "        #cycleAveSqErr = empAveSquareError(trainedParam,pathAndTime,environment[0],startDay,periodLength);\n",
    "        #print(\"\\n\"+\"cycle sqrt of mse = \"+str(numpy.sqrt(cycleAveSqErr)));\n",
    "        #empMSEList.append(100*numpy.sqrt(cycleAveSqErr)/(averagef));\n",
    "        #empMSEList.append(round(numpy.sqrt(2),2));\n",
    "    #print(\"\\n\");\n",
    "    #print(\"Theory MSE pct = \"+str(theoryMse));\n",
    "    #print(\"Average f value =\"+str(averagef));\n",
    "    return empMSElist;\n",
    "\n",
    "regimeVariation = 0.75;\n",
    "regimeBase = [3,2,3,4,3,4,4,4,3,3,4,2,4,3,3,4,3,2];\n",
    "environment = [environGen(18,regimeBase,regimeVariation,18000),regimeBase];\n",
    "indData = [P_I,pathMeanTimes,pathStdOfTimes,[0,0,0,0,0] ];\n",
    "pathAndTime = pathAndTimeGen(18000,indData[0],indData[1],indData[2]);\n",
    "\n",
    "variationDemo = varRegime(pathAndTime,environment,indData,2,regimeVariation);\n",
    "#print(variationDemo);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 5\n",
      "0.63 1.94 1.44 9.17 3.82 6.98 12.0 2.48 7.53 8.17 6.22 6.18 6.22 6.95 5.39 5.98 6.44 6.41 5.71 6.31 5.71 5.88 5.58 6.32 5.57 6.63 5.76 5.97 5.89 6.3 5.43 6.19 6.38 5.39 \n",
      "\n",
      "Train for 10\n",
      "0.77 2.76 1.19 9.84 7.53 9.53 4.31 6.31 7.69 3.87 5.37 7.14 5.96 6.78 5.57 6.1 5.71 5.55 6.92 6.0 5.4 6.1 5.73 5.54 5.26 6.15 5.22 6.31 6.61 5.9 5.76 6.63 6.3 5.93 \n",
      "\n",
      "Train for 20\n",
      "4.2 1.52 3.98 7.58 2.31 3.58 1.2 2.34 6.25 2.98 5.67 7.08 5.84 5.88 5.65 4.73 5.83 6.64 6.2 5.32 6.27 5.01 6.05 5.08 5.88 5.42 5.81 6.21 5.87 6.22 5.51 5.5 6.47 5.77 \n",
      "\n",
      "Train for 40\n",
      "2.59 4.77 4.95 3.34 3.82 1.74 6.02 6.32 5.75 2.5 3.08 5.74 4.73 5.74 4.43 6.37 6.08 5.89 5.79 6.28 6.25 6.26 5.37 6.14 4.77 5.49 5.49 5.83 4.79 5.25 5.31 5.13 5.75 5.63 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0,len(variationDemo)):\n",
    "#    print(variationDemo[i]);\n",
    "\n",
    "for i in range(0,len(variationDemo)):\n",
    "    N = 5*(2**i);\n",
    "    #print(str(\"Train for :\")+str(N));\n",
    "    #print(\" \");\n",
    "    print(\"Train for \"+str(N));\n",
    "    for j in range(0,len(variationDemo[i])):\n",
    "        print(str(round(variationDemo[i][j],2))+\" \",end=\"\");\n",
    "    print(\"\\n\");\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
