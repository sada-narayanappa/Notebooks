{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2e670aab-39a2-4294-98c3-f73373d5159d"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import importlib\n",
    "try:    importlib.reload(Jupytils)\n",
    "except: import Jupytils\n",
    "import logging as log\n",
    "import itertools as it\n",
    "showTopbar('''ARX Model Create''')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from arch.univariate import ARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=LoadDataSet(\"data/test.csv\")\n",
    "dfi=LoadDataSet(\"data/test.inv.xml\", xmlTag=\"Invariant\")\n",
    "dfi['theta1']= dfi.apply (lambda row: [ float(i.strip()) for i in  row['theta'].split(',') if i.strip()], axis=1)\n",
    "dfi.n = dfi.n.astype(int)\n",
    "dfi.m = dfi.m.astype(int)\n",
    "dfi.k = dfi.k.astype(int)\n",
    "dfi.fitness = dfi.fitness.astype(float)\n",
    "dfi.threshold = dfi.threshold.astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#display(HTML(dfi.to_html()))\n",
    "dfi.sort_values(['uName', 'yName'], inplace=True)\n",
    "dfi = dfi.reset_index(drop=True)\n",
    "displayDFs(dfi, showIcons=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#%%writefile inx.py\n",
    "\n",
    "import logging as log\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np;\n",
    "import datetime\n",
    "import getopt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re;\n",
    "import collections\n",
    "import gc\n",
    "import json\n",
    "from Jupytils import Map\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numba import njit\n",
    "\n",
    "def logd(debug = True, *args):\n",
    "    if not debug: return\n",
    "    for a in args:\n",
    "        print(a, sep='', end=' ')\n",
    "\n",
    "log.getLogger().setLevel(log.INFO)\n",
    "\n",
    "\n",
    "# We use this function to computer ARX b/w u & v- ARXModelLR is 100 times faster\n",
    "# For creating model using ARX model from ARCH modellers - see ARXClass.ipynb\n",
    "# than  the LR model hand coded from scratch.\n",
    "#\n",
    "# \n",
    "def Regressors(y, x, n,m,k, debug=False):\n",
    "    x = x.reshape(len(x),1)\n",
    "    logd(f'Regressors {n, m, k}')\n",
    "    offset = max(n, m + k);\n",
    "    llen = len(y) - offset;\n",
    "    logd(debug, f\"Length of each array: {llen}, n+m+k={offset}, Length of Original: {len(y)}\\n\" )\n",
    "    \n",
    "    xxx=[]\n",
    "    for i in range(1, n+1):\n",
    "        logd(debug, f'==>{offset-i} - {offset-i+llen} {llen}\\n' )\n",
    "        xxx.append(y[offset-i:offset-i+llen].reshape((llen,1)));\n",
    "        \n",
    "    for i in range(0, m+1):\n",
    "        upto = len(x) - k\n",
    "        x1 = x[upto-llen-i: upto-i]\n",
    "        #x1 = x[i: i+llen]\n",
    "        xxx.append(x1);\n",
    "    \n",
    "    for i in range(len(xxx)):\n",
    "        logd(debug, \"+==>\" , len(xxx[i]), \"\\n\")\n",
    "        \n",
    "    if (len(xxx) > 0):\n",
    "        xx = np.hstack(xxx)\n",
    "    else:\n",
    "        xx = x\n",
    "        \n",
    "    return xx,offset;\n",
    "\n",
    "# Theta is the parameter vector with last index is the constant of ARX model\n",
    "#\n",
    "def ComputeResid(y, x, theta, n,m,k):\n",
    "    xx, offset= Regressors(y,x, n,m,k)\n",
    "    rs1=np.dot(xx, theta[:-1]) + theta[-1]\n",
    "    return rs1\n",
    "\n",
    "    \n",
    "def ARXModelLR(y, x, n,m,k, debug=False):\n",
    "    xx, offset = Regressors(y, x, n,m,k, debug)\n",
    "    arx = LinearRegression(fit_intercept=True).fit(xx, y[offset:])\n",
    "    ret = np.append(arx.coef_, arx.intercept_)\n",
    "    \n",
    "    # THe following is used until we stabilize the results and then can be removed\n",
    "    ret1 = ret.copy();\n",
    "    ret1[0:n] *= -1;\n",
    "    del xx\n",
    "    return ret, arx, ret1;\n",
    "\n",
    "#u,v,f,c,_,t,n,m,k,_,_,_,etheta=dfi.loc[13]\n",
    "#x=df[u].values    \n",
    "#y=df[v].values\n",
    "#r,_,r1=ARXModelLR (y, x, n, m, k, True)\n",
    "#print(f'{(n,m,k)}, {r}\\n{r1}\\n{etheta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%writefile -a inx.py\n",
    "#Theta is a parameter matrix [n-coeffs, m-coffients, constant]\n",
    "def predict(x, y, n,m,k, theta, t):\n",
    "    s = max(n, (m+k))\n",
    "    if( t < s):\n",
    "        print(\"Hmmm Passing an index i:{} resetting to {}\".format(i,s))\n",
    "        t=s\n",
    "    \n",
    "    if (x is None or len(x) < (m+k+1) ):\n",
    "        #p= list(reversed(y[t-n:t] * -1)) + [0] * (1+m)  + [1]\n",
    "        p= list(reversed(y[t-n:t])) + [0] * (1+m)  + [1]\n",
    "    else:\n",
    "        p= list(reversed(y[t-n:t])) + list(reversed(x[t-m-k:t-k+1])) + [1]\n",
    "\n",
    "    yh = np.sum(np.array(p).dot(theta))\n",
    "    rs = (y[t] - yh)\n",
    "    return yh,rs\n",
    "\n",
    "# Compute the Fitness Score\n",
    "#\n",
    "def FitnessScore(x, y, n,m,k,theta, needArrays=True):\n",
    "    s=max(n,m+k)\n",
    "    denom = np.sum((y[s:]- np.mean(y[s:]))**2)\n",
    "    yhat=np.array(y.copy())\n",
    "    residueFit=[]\n",
    "    sumResidue = 0;\n",
    "    for t in range(s,len(y)):  # <= predict all possible candidates\n",
    "        yyFit,rrFit = predict(x, yhat, n,m,k, theta, t)\n",
    "            \n",
    "        yhat[t] = yyFit\n",
    "        sumResidue += rrFit ** 2\n",
    "        \n",
    "        if (needArrays):\n",
    "            residueFit.append(rrFit)\n",
    "   \n",
    "    fitness = 1- np.sqrt(sumResidue/denom)\n",
    "    return fitness, yhat,residueFit;\n",
    "\n",
    "# Compute best fitness score and return the results\n",
    "#\n",
    "def findBest(y, x):\n",
    "    best=Map({});\n",
    "    x=x.reshape((len(x),1))\n",
    "    fitscore, yh, rs = 0,0,0\n",
    "    best.fitscore = -1;\n",
    "    \n",
    "    for n in range(3):\n",
    "        for m in range(2):\n",
    "            for k in range(3):\n",
    "                theta, arx,theta1 = ARXModelLR(y, x,n,m,k)\n",
    "                fitscore, yh, rs = FitnessScore(x,y,n,m,k, theta, False)\n",
    "                    \n",
    "                #print(f'{(n,m,k)}, {theta}')\n",
    "                if (best.res is None or fitscore > best.fitscore ): \n",
    "                    best.res = theta; best.rs=rs; best.nmk= (n,m,k); best.fitscore = fitscore; \n",
    "                    best.n=n; best.m=m; best.k=k;\n",
    "                    \n",
    "    \n",
    "#    if ('resid' in best.res):\n",
    "#       best.threshold= max(abs(best.res.resid[best.nmk[0]:]) ) * 1.05\n",
    "#    else:\n",
    "    rs1=ComputeResid(y, x, best.res, best.n, best.m, best.k)\n",
    "    yh1=y[-len(rs1):]-rs1\n",
    "    best.threshold=max(abs(yh1)) * 1.05\n",
    "        \n",
    "    #print({f'{len(x), x.shape, len(y), y.shape}'})\n",
    "    #best.cor = np.corrcoef(y,x)[0,1] #np.corrcoef(x,y)[0,0]\n",
    "        \n",
    "    return best;\n",
    "\n",
    "#This will create a Invariant file. Note the CSV file has the following format\n",
    "# Time, A, B, C, D => first columns in time and time series for subsequent columns\n",
    "#\n",
    "def CreateInvariants(file, outFileName=None, columns_from=0, columns_to=100000):\n",
    "    df=pd.read_csv(file)\n",
    "    if ( len(df) <= 2 or len(df.columns) <= 1):\n",
    "        log.info(f\"Not enough data in {file} ... ending\")\n",
    "        raise Exception(f\"Not enough data in the dataframe {file}\")\n",
    "\n",
    "    log.info(f\"Creating invariants using {df.columns[1:]}\" )\n",
    "    \n",
    "    cols = 'uName,yName,fitness,correlation,theta,n,m,k,threshold'.split(',')\n",
    "    dfi1 = pd.DataFrame(columns=cols);\n",
    "    for i,u in enumerate(df.columns[columns_from:]):\n",
    "        if ( i > columns_to):\n",
    "            break;\n",
    "        if ( i == 0 or len(df[u].unique()) <=1 ):\n",
    "            log.debug(f'either index is 0 : index={i} or not enough unique values in {u}')\n",
    "            continue;\n",
    "                    \n",
    "        for v in df.columns[1:]:\n",
    "            if (u == v ):\n",
    "                continue;\n",
    "            if (len(df[v].unique()) <= 2 ):\n",
    "                log.debug(f'not enough unique values in {u}')\n",
    "                continue;\n",
    "            x=df[u].values    \n",
    "            y=df[v].values\n",
    "            print(f\"Finding Best of {i}/{len(df.columns)} {u} and {v} \\r\", end='')\n",
    "            \n",
    "            ret = findBest(y, x);\n",
    "            theta = \",\".join([str(c) for c in ret.res])\n",
    "            corr = np.corrcoef(x,y)[0][1]\n",
    "            \n",
    "            inv1 = [u,v,ret.fitscore, corr, theta, ret.n, ret.m, ret.k, ret.threshold]\n",
    "            log.debug(f\"{inv1}\" )\n",
    "            dfi1.loc[len(dfi1)] = inv1\n",
    "    \n",
    "    dfi1.sort_values(['uName', 'yName'], inplace=True)\n",
    "    if ( outFileName is not None):\n",
    "        dfi1.to_csv(outFileName, index=False)\n",
    "    \n",
    "    return dfi1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a inx.py\n",
    "\n",
    "GLOBAL_ARGS=defaultdict(int)\n",
    "def Usage():\n",
    "    print('''Usage: sys.argv[0]} csvfile <output file> [from -f columnnumber] [to -t columnnumner]\n",
    "          Ex: sys.argv[0]}  -f 0 -t 10 test.csv test.inv.0.csv\n",
    "          ''')\n",
    "def getargs(opts=\"hf:t:\"): \n",
    "    try:\n",
    "        opts, args = getopt.getopt(sys.argv[1:],opts)\n",
    "    except getopt.GetoptError:\n",
    "        Usage(\"Exception~~\")\n",
    "        \n",
    "    for opt, arg in opts:\n",
    "        if opt == '-h': \n",
    "            Usage();\n",
    "        GLOBAL_ARGS[opt] = 1 if not arg else arg;\n",
    "    GLOBAL_ARGS['__ARGS__'] = args\n",
    "    \n",
    "def inJupyter():\n",
    "    try:\n",
    "        get_ipython\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    global GLOBAL_ARGS\n",
    "    args = GLOBAL_ARGS['__ARGS__']\n",
    "    if (len(args) < 2 ): \n",
    "        Usage();\n",
    "        return;\n",
    "    csvp = args[0]\n",
    "    outp = args[1]\n",
    "    cFrom = int(GLOBAL_ARGS['-f']) if ('-f' in GLOBAL_ARGS) else 0\n",
    "    cTo = int(GLOBAL_ARGS['-t']) if ('-t' in GLOBAL_ARGS) else 100000\n",
    "    CreateInvariants( csvp, outp, cFrom, cTo)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    if (not inJupyter()):\n",
    "        getargs(\"-hf:t:\")\n",
    "        main()\n",
    "        print(\"All Done ***\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfii = CreateInvariants(\"data/test.csv\", '/tmp/test/test.inv.csv', 0 , 3)\n",
    "displayDFs(dfii);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(len(dfi)):\n",
    "    loc=i\n",
    "    u,v,f,c,_,t,n,m,k,thr,_,_,etheta=dfi.loc[loc]\n",
    "    x=df[u].values    \n",
    "    y=df[v].values\n",
    "    best=findBest(y,x)\n",
    "    ret = best\n",
    "    inv1 = [u,v,ret.fitscore[0], 1, ret.res, ret.nmk[0], ret.nmk[1], ret.nmk[2], ret.threshold]\n",
    "    print(u,v,ret.fitscore[0], \",\".join([str(c) for c in ret.res]), ret.nmk[0], ret.nmk[1], ret.nmk[2], ret.threshold)\n",
    "    print(u,v,f,t,n,m,k,thr,_,_,etheta)\n",
    "    if ( not np.allclose(f, best.fitscore) or (n,m,k) != best.nmk  or not np.allclose(thr, best.threshold)):\n",
    "        print(f'{u,v} Fit: {f} === {best.fitscore}, \\nnmk: {(n,m,k)} === {best.nmk}, \\n Threshhold: {thr} === {best.threshold}')\n",
    "        \n",
    "    break;\n",
    "#def testCreate()\n",
    "#CreateInvariants(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testARXModelLR(dfi, loc=0, log=True):\n",
    "    u,v,f,c,_,t,n,m,k,_,_,_,theta=dfi.loc[loc]\n",
    "\n",
    "    x=df[u].values    \n",
    "    y=df[v].values\n",
    "    x1=x.reshape((len(x),1))\n",
    "    logd(log,f'{loc}: {u,v} n,m,k ={n,m,k} theta={ np.array(theta)}' )\n",
    "    #res, arx = ARXModelOld(y, x1, n, m, k);\n",
    "    ret, arx, ret1 = ARXModelLR(y, x1, n, m, k);\n",
    "    np.set_printoptions(precision=6)\n",
    "    logd(log, ret, ret1)\n",
    "    \n",
    "    comp = np.allclose(ret1,theta)\n",
    "    logd(log, \"Matched: \", comp)\n",
    "    if ( not comp):\n",
    "        print (f\"{loc} {n,m,k} {u, v } Not Matched\\n {ret1} \\n {theta}\")\n",
    "    return ret, comp, ret1, theta;\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    ret, comp,ret1, etheta = testARXModelLR(dfi, i, False)\n",
    "    \n",
    "print(\"If there was mot match you would see a print out! Nothing printed means all is well\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFitnessScore(dfi, loc = 0, log=True):\n",
    "#loc=9\n",
    "    u,v,f,c,_,t,n,m,k,_,_,_,theta=dfi.loc[loc]\n",
    "\n",
    "    x=df[u].values    \n",
    "    y=df[v].values\n",
    "    x1=x.reshape((len(x),1))\n",
    "    #logd(log,f'{loc}: {u,v} n,m,k ={n,m,k} theta={ np.array(theta)}' )\n",
    "    theta1, arx,_ = ARXModelLR(y,x1,n,m,k)\n",
    "    fitscore,yh,rs = FitnessScore(x,y,n,m,k, theta1, True)\n",
    "\n",
    "    ret = np.allclose(fitscore, f)\n",
    "    if (not ret):\n",
    "        print(f\"=> {loc} Score No Matched {f}: {n,m,k} \\n {f} {theta}\\n {fitscore}{theta1}\")\n",
    "        #return (ret)\n",
    "\n",
    "for i in range(len(dfi)):\n",
    "    testFitnessScore(dfi, i, False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testCompareInvCSV(invFile, invCSV, log=True):\n",
    "    dfi1=LoadDataSet( invFile, xmlTag=\"Invariant\")\n",
    "    dfi1['theta1']= dfi1.apply (lambda row: [ float(i.strip()) for i in  row['theta'].split(',') if i.strip()], axis=1)\n",
    "    dfi1.n = dfi1.n.astype(int)\n",
    "    dfi1.m = dfi1.m.astype(int)\n",
    "    dfi1.k = dfi1.k.astype(int)\n",
    "    dfi1.fitness = dfi1.fitness.astype(float)\n",
    "    dfi1.threshold = dfi1.threshold.astype(float)\n",
    "\n",
    "\n",
    "    dfi2 = pd.read_csv('/tmp/test.inv')\n",
    "    dfi2['theta1']= dfi2.apply (lambda row: [ float(i.strip()) for i in  row['theta'].split(',') if i.strip()], axis=1)\n",
    "    dfi2.n = dfi2.n.astype(int)\n",
    "    dfi2.m = dfi2.m.astype(int)\n",
    "    dfi2.k = dfi2.k.astype(int)\n",
    "    dfi2.fitness = dfi2.fitness.astype(float)\n",
    "    dfi2.threshold = dfi2.threshold.astype(float)\n",
    "\n",
    "    \n",
    "    u,v,f,c,_,t,n,m,k,_,_,_,theta=dfi.loc[loc]\n",
    "\n",
    "    x=df[u].values    \n",
    "    y=df[v].values\n",
    "    x1=x.reshape((len(x),1))\n",
    "    #logd(log,f'{loc}: {u,v} n,m,k ={n,m,k} theta={ np.array(theta)}' )\n",
    "    theta1, arx,_ = ARXModelLR(y,x1,n,m,k)\n",
    "    fitscore,yh,rs = FitnessScore(x,y,n,m,k, theta1, True)\n",
    "\n",
    "    ret = np.allclose(fitscore, f)\n",
    "    if (not ret):\n",
    "        print(f\"=> {loc} Score No Matched {f}: {n,m,k} \\n {f} {theta}\\n {fitscore}{theta1}\")\n",
    "        #return (ret)\n",
    "\n",
    "testCompareInvCSV(\"data/test.inv.xml\", '/tmp/test.inv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dfi[(dfi['uName'] == 'A') & (dfi['yName'] == 'D')]\n",
    "dfi1=LoadDataSet( \"data/test.inv.xml\", xmlTag=\"Invariant\")\n",
    "dfi2 = pd.read_csv('/tmp/test/test.inv.csv')\n",
    "\n",
    "dfi1['theta1']= dfi1.apply (lambda row: [ float(i.strip()) for i in  row['theta'].split(',') if i.strip()], axis=1)\n",
    "dfi1.n = dfi1.n.astype(int)\n",
    "dfi1.m = dfi1.m.astype(int)\n",
    "dfi1.k = dfi1.k.astype(int)\n",
    "dfi1.fitness = dfi1.fitness.astype(float)\n",
    "dfi1.threshold = dfi1.threshold.astype(float)\n",
    "\n",
    "dfi2['theta1']= dfi2.apply (lambda row: [ float(i.strip()) for i in  row['theta'].split(',') if i.strip()], axis=1)\n",
    "dfi2.n = dfi2.n.astype(int)\n",
    "dfi2.m = dfi2.m.astype(int)\n",
    "dfi2.k = dfi2.k.astype(int)\n",
    "dfi2.fitness = dfi2.fitness.astype(float)\n",
    "dfi2.threshold = dfi2.threshold.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfi)):\n",
    "    testFitnessScore(dfi, i, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,v,f,c,_,t,n,m,k,thr,_,_,theta=dfi2.loc[loc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi2"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {
    "c89f7a77-3ed6-4118-9f7f-4018f43f451a": {
     "id": "c89f7a77-3ed6-4118-9f7f-4018f43f451a",
     "prev": null,
     "regions": {
      "0586cd23-72f2-4129-a02c-92a94b6fa5b0": {
       "attrs": {
        "height": 0.4,
        "width": 0.4,
        "x": 0.5,
        "y": 0.1
       },
       "content": {
        "cell": "c3741e5c-d261-4400-bc2b-29e0bbbdf92b",
        "part": "outputs"
       },
       "id": "0586cd23-72f2-4129-a02c-92a94b6fa5b0"
      },
      "4f93db58-9106-4912-a80a-1f7b319bd2c8": {
       "attrs": {
        "height": 0.4,
        "width": 0.4,
        "x": 0.5,
        "y": 0.5
       },
       "content": {
        "cell": "2c8efb89-cfe8-4215-80a7-f4a6e58a0244",
        "part": "outputs"
       },
       "id": "4f93db58-9106-4912-a80a-1f7b319bd2c8"
      },
      "67f6bc87-1028-4398-b944-0f62b2995a1c": {
       "attrs": {
        "height": 0.4,
        "width": 0.4,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "31beed05-932a-4848-b329-f5d0893ced3a",
        "part": "outputs"
       },
       "id": "67f6bc87-1028-4398-b944-0f62b2995a1c"
      },
      "77a2bdde-9497-470b-a118-74ec474495d7": {
       "attrs": {
        "height": 0.4,
        "width": 0.4,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "e798bbb6-f56e-4cb9-83bf-290af445fa17",
        "part": "outputs"
       },
       "id": "77a2bdde-9497-470b-a118-74ec474495d7"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
